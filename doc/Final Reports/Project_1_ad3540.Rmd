---
title: "Project 1 - Song Analysis"
author: "Alexandra DeKinder"
output: html_notebook

---




Many different things define a decade, but few more so than the music. We remember the 60's for the rise of bands like the Beatles that redefined music, and the 80's for the loud rock and roll hair bands that morphed into rebellious punk. In this project I will investigate these differences and build a model that uses characteristics of songs and their lyrics to predict the decade the song was created. 

### Data Processing and Exploration

```{r Libraries, echo=FALSE, message=FALSE}
library(readr)
library(tibble)
library(sentimentr)
library(gplots)
library(dplyr)
library(tm)
library(syuzhet)
library(factoextra)
library(beeswarm)
library(scales)
library(RColorBrewer)
library(RANN)
library(topicmodels)
library(MASS)
library(class)
library(psych)
library(gmodels)
library(ggpubr)
library(corrplot)
```

I will use the cleaned data that is generated from the Text_Processing.Rmd file. This file includes the variables listed below:

```{r Importing Data, echo=FALSE}
load("~/Documents/GitHub/fall2019-proj1--alexdekinder/output/processed_lyrics.RData")
colnames(dt_lyrics)
```

Before I begin to build a model, I first want to investigate the data.

```{r Data Charactersitics}
#Number of songs
nrow(dt_lyrics)

#The different genres represented
levels(as.factor(dt_lyrics$genre))

#The number of different artistis represented
count<-levels(as.factor(dt_lyrics$artist))
length(count)

#Date range of the data
min(dt_lyrics$year)
max(dt_lyrics$year)

```

When looking at the date range of the songs, we see that there is a song with the year 112. In order to determine the reason for this we need to further inspect the data. 

One way to check to see if there are any other odd dates in the data, we can look at any observations with a year less than 1000.

```{r Error Check}

#Checking for other outliers
dt_lyrics[dt_lyrics$year < 1000,]


```


The above outut shows that there are actually two observations with dates outside of a normal range. 
One solution would be if there was clearly an error, like a date should be 1992 but is written as 992, then one could infer that the 1 was left off and just correct the data point manually. In this case, it does not appear that this is the obvious error so in order to be safe I will remove these two observations.


```{r Data Cleaning}

#Removing incorrect observations
clean_lyrics <- dt_lyrics %>%
  filter(year > 1000)
```


Now, for my response variable I will be using the decade the the song was written. The given data set gives the year the song was written so I will need to create a new column that contains the decade of the song.


```{r Creating Decade Variable}

clean_lyrics <- clean_lyrics %>%
  mutate(year = as.numeric(year)) %>%
  mutate(Decade = if_else(year < "1970", "1960",
         if_else( year < "1980" & year > "1969", "1970",
                                 if_else(year < "1990" & year > "1979", "1980",
                                         if_else(year < "2000" & year > "1989", "1990",
                                                 if_else(year < "2010" & year > "1999", "2000",
                                                         if_else(year > "2009", "2010", "NA")))))))


```

I will add the number of words in the song (e.g song length) as another possible predictor variable.

```{r Creating Song Length}

clean_lyrics <- clean_lyrics %>%
  mutate(Length = sapply(strsplit(lyrics, " "), length))


```

The last predictor I will add is the overall sentiment of the song. For this sentiment analysis I will be using a numeric sentiment score$^3$.


```{r Sentiment}

clean_lyrics <- clean_lyrics %>%
  mutate(sentiment=get_sentiment(lyrics)) #Getting sentiment score

clean_lyrics$sentiment <- round(clean_lyrics$sentiment,3) #Rounding score values
  
#I will visulaize the sentiment score by decade in a bar chart

graph.data <- clean_lyrics %>%
  group_by(Decade) %>%
  summarise(Avg.Sentiment = mean(sentiment))

ggplot(graph.data,aes(x=Decade,y=Avg.Sentiment,fill=Decade)) +
  geom_bar(stat="identity") + theme_minimal() +
  ggtitle("Average Sentiment Score by Decade")
```



In the graph, it is clear the average sentiment score varies greatly between the decades. Before I build the model, I will explore the data further using visuals.

```{r Length of Song by Decade Graph, echo=FALSE}
graph.data <- clean_lyrics %>%
  group_by(Decade) %>%
  summarise(Avg.Length = mean(Length))

ggplot(graph.data,aes(x=Decade,y=Avg.Length,fill=Decade)) +
  geom_bar(stat="identity") + theme_minimal() +
  ggtitle("Average Number of Words per Song by Decade") +
  ylab("Average # of Words")
```

The graph above shows that the average number of words in a song has steadily increased over the decades. Since I do not have the run time of the songs, this can be interpreted as either songs have gotten longer, or that song lyrics have become more complex and include more words.


```{r Genre by Decade Graph, echo=FALSE}
graph.data <- clean_lyrics %>%
  group_by(Decade, genre) %>%
  tally()

#Count of Songs by Decade
table.data <- graph.data %>%
  group_by(Decade) %>%
  summarise(Song_Count = sum(n))

table.data

ggplot(data = graph.data, aes(x = "", y = n, fill = genre )) + 
    geom_bar(stat = "identity", position = position_fill()) +
    coord_polar(theta = "y") +
    facet_wrap(~ Decade)  +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          panel.grid  = element_blank()) + 
    theme(legend.position='bottom') + 
    guides(fill=guide_legend(nrow=2, byrow=TRUE)) +
  ggtitle("Songs by Genre Across Decades") 


  
```



```{r Artists with multiple Decades, echo=FALSE}

graph.data <- clean_lyrics %>%
  group_by(artist, Decade) %>%
  tally() %>%
  dplyr::select(artist,Decade) %>%
  group_by(artist) %>%
  tally()



ggplot(graph.data, aes(x=n))+
  geom_histogram(color="black", fill="lightblue",binwidth = 1) +
  xlab("Number of Decades") +
  ggtitle("Count of Decades Spanned by Artsits")

```

The above graphics highlight some important features of the data. While having variability in the length of song and sentiment scores for each decade is a good thing, the fact that the majority of our songs are from the 2000's and 2010's could make building a model challenging. Also, the histogram highlighting the number of decades spanned by artists also has model building implications. Since most of the artists are only present for one or two decades, I will be removing them from the model. Keeping the artist as a predictor would make it too easy to determine the decade and I would like to focus on the characterstics of the songs themselves.

```{r Removing Artist, echo=FALSE}

final_lyrics <- clean_lyrics %>%
  dplyr::select(-artist)


```


### Model Building

Before I build my classification model, I am going to visualize the correlation between variables in a correlation plot. 


#### Correlation Plot


```{r Correlation Plot}

plot.data <- final_lyrics %>%
  dplyr::select(Decade, Length, sentiment)#Selecting the numeric variables

plot.data <- plot.data %>%
  mutate(Decade = as.numeric(Decade)) %>%
  mutate(Length = as.numeric(Length)) %>%
  mutate(sentiment = as.numeric(sentiment))

cor.plot <- cor(plot.data)

corrplot(cor.plot, method="color")

```

In the correlation plot we can see that length of the song correlates somewhat with decade; however, sentiment appears to have little correaltion. While this is not ideal, it does not mean that certain classification algorithms will not work.

In the next section I will use KNN clustering to see if that is able to put songs into the correct decade.


#### KNN Clustering

KNN clustering$^{1,4}$, at a high level, uses euclidean distance between data to classify the data into groups. KNN is a supervised algorithm, while K-Means is an unsupervised algorithm. KNN works best with numeric data so I will need to change the format of my data so that every variable is numeric. I will also normalize my numeric variables so that the euclidean distances calculated in the algorithm are all at the same scale.


```{r KNN}
#First I need to split the data into training and test sets
set.seed(1234)
train.rows <- sample(1:nrow(final_lyrics),.80*nrow(final_lyrics))

#Before I run KNN, I will normalize the numeric predictors and dummy code the genre variable

normalize <- function(x) {(x-min(x))/(max(x)-min(x))}

norm.final_lyrics <- final_lyrics

norm.final_lyrics$sentiment <- normalize(final_lyrics$sentiment) #Normalizing variables
norm.final_lyrics$Length <- normalize(final_lyrics$Length)

Genre.data <-as.data.frame(dummy.code(norm.final_lyrics$genre)) #Dummy coding genre 

norm.final_lyrics<-norm.final_lyrics[,-c(1:6)]
norm.final_lyrics<-cbind(norm.final_lyrics,Genre.data) #Combining all the processed variables back together


#Separating training set

lyrics_train <- norm.final_lyrics[train.rows,]

#Separating test set

lyrics_test <-  norm.final_lyrics[-train.rows,]

#Extract decade column since that is the response variable

lyrics_decade <-(final_lyrics[train.rows,"Decade"])
lyrics_train <- lyrics_train[,-1]


lyrics_test_decade <- (final_lyrics[-train.rows,"Decade"])
lyrics_test <- lyrics_test[,-1]


#Now I can run the knn function

knn.predict <- knn(lyrics_train,lyrics_test,cl=as.factor(lyrics_decade$Decade),k=7)


```


```{r Confusion Matrix, echo=FALSE}


#Extracting predictions
class_comparison <- data.frame(knn.predict,lyrics_test_decade)
names(class_comparison) <-c("PredictedDecade","ObservedDecade")


#Confusion Matrix
tab<-CrossTable(x = class_comparison$ObservedDecade, y = class_comparison$PredictedDecade, prop.chisq=FALSE, prop.c = FALSE, prop.r = FALSE, prop.t = FALSE)


```




```{r Accuracy}
results <- as.matrix(tab$t)

diagonal<-diag(results)
accuracy <- sum(diagonal)/nrow(lyrics_test)
round(accuracy,2)

```



While at first glance it may seem that a 73% accuracy rate is not bad, upon closer inspection, there are some serious issues with the KNN clustering method. While the algorithm did well with the songs in the 2000's and 2010's, it did not correctly assign any of the songs from the earlier decades, except for 1 in the 1990's. A reason for this is because this data is known as imbalanced data. As it was shown before, a majority of the songs in the data set are from the most recent two decades and because of this, the KNN algorithm will try to assign most of the observations in the test set to these decades. Imbalanced data is not an uncommon problem and there are several methods to use in this situation.


The first method is re-sampling the data$^2$. Essentially, this means taking less data from the over-represented classes and more from the under-represented classes. Since the data set is fairly large, I will use under-sampling for songs in the 2000's and 2010's. Another method of over-sampling is SMOTE, which stands for synthetic minority over-sampling technique. SMOTE generates fake samples in the minority class. A non-sampling method would be to add weight to the minority classes in the algorithm. 



```{r New KNN, echo=FALSE}
#First split the data into training and test sets
set.seed(1234)
train.rows <- sample(1:nrow(final_lyrics),.80*nrow(final_lyrics))

#Normalizing the numeric predictors and dummy code the genre variable

norm.final_lyrics <- final_lyrics

norm.final_lyrics$sentiment <- normalize(final_lyrics$sentiment) #Normalizing variables
norm.final_lyrics$Length <- normalize(final_lyrics$Length)

Genre.data <-as.data.frame(dummy.code(norm.final_lyrics$genre)) #Dummy coding genre 

norm.final_lyrics<-norm.final_lyrics[,-c(1:6)]
norm.final_lyrics<-cbind(norm.final_lyrics,Genre.data) #Combining all the processed variables back together


#Separating training set

lyrics_train <- norm.final_lyrics[train.rows,]

#Separating test set

lyrics_test <-  norm.final_lyrics[-train.rows,]
```


```{r Rebalancing Training Set}
#Data rebalancing, this must be done after the data is split and only on the training set
#I will pull out 50% of the data from the 2000's and 2010's

set.seed(1234)

removed.rows.2000 <- sample(1:nrow(lyrics_train[lyrics_train$Decade == "2000", ]), #Randomly selecting rows
                       .50*nrow(lyrics_train[lyrics_train$Decade == "2000", ]))

removed.rows.2010 <- sample(1:nrow(lyrics_train[lyrics_train$Decade == "2010", ]),
                       .50*nrow(lyrics_train[lyrics_train$Decade == "2010", ]))


balanced_lyrics_train <- lyrics_train[-c(removed.rows.2000,removed.rows.2010),]


#Extract decade column since that is the response variable

lyrics_decade <-(balanced_lyrics_train[,"Decade"])
balanced_lyrics_train <- balanced_lyrics_train[,-1]


lyrics_test_decade <- (lyrics_test[,"Decade"])
lyrics_test <- lyrics_test[,-1]


#Now we run the knn function

knn.predict <- knn(balanced_lyrics_train,lyrics_test,cl=as.factor(lyrics_decade),k=7)


```


```{r Confusion Matrix 2, echo=FALSE}


#Extracting predictions
class_comparison <- data.frame(knn.predict,lyrics_test_decade)
names(class_comparison) <-c("PredictedDecade","ObservedDecade")


#Confusion Matrix
tab<-CrossTable(x = class_comparison$ObservedDecade, y = class_comparison$PredictedDecade, prop.chisq=FALSE, prop.c = FALSE, prop.r = FALSE, prop.t = FALSE)


```



```{r Accuracy 2}
results <- as.matrix(tab$t)

diagonal<-diag(results)
accuracy <- sum(diagonal)/nrow(lyrics_test)
round(accuracy,2)

```



### Conclusions

When I rebalanced the data and ran the KNN algorithm again the accuracy actually was much lower. There are several key takeaways from this. First, even wih removing 50% of the data from the 2000's and 2010's, the data is still imbalanced. In order to really balance the classes, a combination of under- and over-sampling could be a better approach. Second, another classification method completely could be a better way to answer the posed question. Finally, these song charactersitics might be not particulary useful in classifying songs into their decade. 

Data analysis questions are often a process, during which one will realize a selected approach is not working and must look to new methods to try and solve the problem. Also, one might conclude that asking a different question all together might lead to a more useful solution. No matter what the model says, our decades will continue to be defined by their music, and hopefully soon we can unlock the secret to what made each era of music so unique.


### References

1. "K-Nearest Neighbor: An Introductory Example." K-Nearest Neighbor: An Introductory Example. 17 Sept. 2019
      
      <https://quantdev.ssri.psu.edu/sites/qdev/files/kNN_tutorial.html>
      
      
2. Nabi, Javaid. "Machine Learning - Multiclass Classification with Imbalanced Dataset." 
  
      Medium. 22 Dec. 2018. Towards Data Science. 17 Sept. 2019
      
      <https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c        
        1a>.
        
3. Nishida, Kan. "Twitter Sentiment Analysis - Scoring by Sentence." Medium. 11 July 2016. 

      Learn data science. 18 Sept. 2019     
      
      <https://blog.exploratory.io/twitter-sentiment-analysis-scoring-by-sentence-b4d455de3560>
  
        
4. Sirohi, Kshitiz. "K-nearest Neighbors Algorithm with Examples in R (Simply Explained knn)".

      Medium. 30 Dec. 2018. Towards Data Science. 17 Sept. 2019
      
      <https://towardsdatascience.com/k-nearest-neighbors-algorithm-with-examples-in-r-simply-explained-knn-1f2c88d         
        a405c>
      
  

